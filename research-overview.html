<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=us-ascii">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 11">
<meta name=Originator content="Microsoft Word 11">
<link rel=File-List href="research-overview_files/filelist.xml">
<title>Patrice Godefroid's Research Overview (1989-2021)</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceType"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceName"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Patrice Godefroid</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor>Patrice Godefroid</o:LastAuthor>
  <o:Revision>21</o:Revision>
  <o:TotalTime>95</o:TotalTime>
  <o:Created>2007-03-30T20:21:00Z</o:Created>
  <o:LastSaved>2007-04-18T18:59:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>1208</o:Words>
  <o:Characters>6891</o:Characters>
  <o:Company>Microsoft Corporation</o:Company>
  <o:Lines>57</o:Lines>
  <o:Paragraphs>16</o:Paragraphs>
  <o:CharactersWithSpaces>8083</o:CharactersWithSpaces>
  <o:Version>11.8122</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:Zoom>120</w:Zoom>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" LatentStyleCount="156">
 </w:LatentStyles>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1 -369098753 63 0 4129279 0;}
@font-face
	{font-family:"\@Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1 -369098753 63 0 4129279 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
p
	{mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
span.SpellE
	{mso-style-name:"";
	mso-spl-e:yes;}
span.GramE
	{mso-style-name:"";
	mso-gram-e:yes;}
@page Section1
	{size:8.5in 11.0in;
	margin:1.0in 1.25in 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-ansi-language:#0400;
	mso-fareast-language:#0400;
	mso-bidi-language:#0400;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="8194"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body bgcolor=white lang=EN-US style='tab-interval:.5in'>

<div class=Section1>

<p class=MsoNormal align=center style='text-align:center'><b><span
style='font-family:"Arial Unicode MS"'>Patrice <span class=SpellE>Godefroid&#8217;s</span>
Research Overview<o:p></o:p></span></b></p>

<p class=MsoNormal align=center style='text-align:center'><b><span
style='font-family:"Arial Unicode MS"'>September 2021</span></b><span
style='font-family:"Arial Unicode MS"'><o:p></o:p></span></p>

<p><span style='font-family:"Arial Unicode MS"'>My main research area during
the last 32 years has been <i style='mso-bidi-font-style:normal'>software model
checking</i> in a broad sense. Here are some main themes. (I also worked on many
other smaller projects on other topics that cannot be summarized here -- please
see my list of publications for more information on those.) <o:p></o:p></span></p>

<p><b><span style='font-family:"Arial Unicode MS"'>Partial-Order Reduction</span></b><span
style='font-family:"Arial Unicode MS"'><o:p></o:p></span></p>

<p><span style='font-family:"Arial Unicode MS"'>In 1988, I started
doing research under the supervision of Professor Pierre <span
class=SpellE>Wolper</span> on what is now known as <i
style='mso-bidi-font-style:normal'>partial-order
reduction</i>. Partial-order reduction (POR) denotes a family of
algorithmic techniques for pruning the state spaces of concurrent
reactive programs in such a way that parts of the state space that are
pruned away are guaranteed not to contain error states of a specific
type, such as deadlocks. POR can considerably speed up verification by
model checking, and is nowadays implemented in many model
checkers. With my advisor Pierre <span class=SpellE>Wolper</span> and
collaborators Gerard <span class=SpellE>Holzmann</span> and Didier
<span class=SpellE>Pirottin</span>, we pioneered the development of
POR, together with other prominent contributors such as <span
class=SpellE>Doron</span> <span class=SpellE>Peled</span> and <span
class=SpellE>Antti</span> <span class=SpellE>Valmari</span>. My own
work on POR culminated in January 1996 with the publication of my PhD
thesis in Springer's <i style='mso-bidi-font-style: normal'>Lecture
Notes in Computer Science</i> series. This work was the co-recipient
of the CAV 2014 Award. <o:p></o:p></span></p>

<p><b><span style='font-family:"Arial Unicode MS"'>Software Model Checking via
Systematic Testing: <span class=SpellE>VeriSoft</span><o:p></o:p></span></b></p>

<p><span style='font-family:"Arial Unicode MS"'>A year or so after joining Bell
Labs in 1994, I started working on software model checking, that is, how to
broaden the scope of model checking from abstract software systems (specified
in modeling languages) to concrete software systems (described using
programming languages). In 1996, I designed and implemented a first version of <span
class=SpellE>VeriSoft</span>, the <i>first model checker for analyzing software
written in mainstream programming languages</i> such as C and C++. The main idea
behind <span class=SpellE>VeriSoft</span> is simple: like a traditional
model checker computes the product of finite-state machines described in some
modeling language, <span class=SpellE>VeriSoft</span> dynamically computes the product of
operating-system (Unix-like) processes described in any programming language.
Several technical innovations made this possible: the use of a run-time
scheduler to systematically drive process executions, a construct to simulate <span
class=SpellE>nondeterminism</span> at run-time, and the use of partial-order
reduction to make a search in the state space of concurrent OS processes
tractable even without storing any intermediate states in memory. Many of these
features have now been adopted in other software model checkers (like Java <span
class=SpellE>PathFinder</span>, CMC, CHESS, etc.). <o:p></o:p></span></p>

<p><span style='font-family:"Arial Unicode MS"'>From 1996 to 2001, I worked
mostly on developing <span class=SpellE>VeriSoft</span> further. With several
Bell Labs colleagues, we investigated many extensions, described in several
published papers. We also started applying <span class=SpellE>VeriSoft</span>
to check the correctness of various software applications inside Lucent
Technologies. After several successful applications, <span class=SpellE>VeriSoft</span>
was also considered in 1999 for a Lucent-funded start-up. Working with Lucent's
venture-capitalist team was an enlightening experience. That same year, I
taught a course (mostly on <span class=SpellE>VeriSoft</span>) at <st1:place
w:st="on"><st1:PlaceName w:st="on">Stanford</st1:PlaceName> <st1:PlaceType
 w:st="on">University</st1:PlaceType></st1:place> hosted by Professor
 David Dill, another valuable experience (teaching a new course takes
 a lot of time!). Meanwhile, <span class=SpellE>VeriSoft</span> was
 gaining traction in some development and testing groups where its use
 contributed to finding several expensive, customer-visible bugs in
 various <span class=GramE>Lucent</span> products.  Since 1999, <span
 class=SpellE>VeriSoft</span> has also been publicly available outside
 Lucent and has been licensed to hundreds of users in industry and
 academia in more than 25 countries. In 2001, I was promoted to
 &quot;distinguished member of the technical staff&quot; of Bell Labs
 for essentially my work on <span class=SpellE>VeriSoft</span> and its
 successful applications in Lucent. <o:p></o:p></span></p>

<p><b><span style='font-family:"Arial Unicode MS"'>Software Model Checking via
Abstraction: May/Must Abstractions, 3-Valued Temporal Logics, and Generalized
Model Checking<o:p></o:p></span></b></p>

<p><span style='font-family:"Arial Unicode MS"'>Around 2000, another approach
to software model checking started to emerge: the static approach. Unlike <span
class=SpellE>VeriSoft</span>, static software model checkers parse the source
code of the software to be checked, compute a conservative abstraction of the
code, and then perform model checking on this abstraction. One of the
pioneering projects in that area is SLAM, a static software model checker for C
code, developed at Microsoft Research originally by Tom Ball and <span
class=SpellE>Sriram</span> <span class=SpellE>Rajamani</span>. From 2001 to
2004, with Glenn <span class=SpellE>Bruns</span>, <span class=SpellE>Radha</span>
<span class=SpellE>Jagadeesan</span> and Michael <span class=SpellE>Huth</span>,
we developed a new framework for static software model checking that uses
may/must abstractions instead of may-only conservative abstractions. With such
abstractions, both proofs and counterexamples (bugs) are now guaranteed to be
sound, by construction. We also showed that verification results can sometimes
be more precise with <i style='mso-bidi-font-style:normal'>generalized model
checking</i>, which checks whether there exists a concretization of an
abstraction satisfying a temporal property. From a theoretical point of view,
generalized model checking is an interesting problem since it generalizes both
model checking (when the abstraction is complete) and <span class=SpellE>satisfiability</span>
(when the abstraction is completely unknown), probably the two most studied
problems related to temporal logic and verification. From a practical point of
view, our work in this area helps explain the foundation of static software
model checking. <o:p></o:p></span></p>

<p><b><span style='font-family:"Arial Unicode MS"'>Automating Software Testing
using Program Analysis: DART and SMART<o:p></o:p></span></b></p>

<p><span style='font-family:"Arial Unicode MS"'>In 2004, I started working with
renewed energy on how to extend the <span class=SpellE>VeriSoft</span> approach
(aka software model checking via systematic testing) to deal with data-driven
applications (after a first attempt described in a PLDI 1998 paper). With Nils <span
class=SpellE>Klarlund</span> and <span class=SpellE>Koushik</span> <span
class=SpellE>Sen</span> (both funded by my NSF grant with my Bell Labs
colleagues Dennis Dams and <span class=SpellE>Kedar</span> <span class=SpellE>Namjoshi</span>),
we implemented a first version of <i style='mso-bidi-font-style:normal'>Directed
Automated Random Testing</i>, or DART for short, a new approach to automate
testing that combines three main techniques: (1) <i style='mso-bidi-font-style:
normal'>automated</i> interface extraction from source code, (2) <i
style='mso-bidi-font-style:normal'>random</i> testing at that interface, and
(3) dynamic test generation to <i style='mso-bidi-font-style:normal'>direct</i>
executions along alternative program paths. The main strength of DART is that
testing can be performed completely automatically on any program that compiles,
as there is no need to manually write any test driver or harness code. Also,
whenever a symbolic expression cannot be generated for an expression involving
some input, the concrete value of that input can be used to simplify this
expression, which allows dynamic test generation to drive executions through
program statements that purely-static test generation cannot handle.<o:p></o:p></span></p>

<p><span style='font-family:"Arial Unicode MS"'>A DART directed search attempts
to sweep through all the feasible execution paths of a program using dynamic
test generation:<span style='mso-spacerun:yes'>&nbsp; </span>the program under
test is first executed on some random or well-formed input, symbolic
constraints on inputs are gathered at conditional branches during that run, and
then a constraint solver is used to generate variants of the previous inputs in
order to steer the next execution of the program towards an alternative program
branch. This process is repeated until <span class=GramE><i style='mso-bidi-font-style:
normal'>all</i><span style='mso-spacerun:yes'>&nbsp; </span>(</span>in
practice, many) feasible program paths of the program are executed, while
detecting various types of errors using run-time checking tools, like Purify,
for instance. DART can thus be viewed as one way of combining static (interface
extraction, symbolic execution) and dynamic (testing, run-time checking)
program analysis with model-checking techniques (systematic state-space
exploration). <o:p></o:p></span></p>

<p><span style='font-family:"Arial Unicode MS"'>Obviously, systematically
executing all feasible program paths does not scale to large, realistic
programs. In 2006, I developed a variant of the DART search algorithm that
performs dynamic test generation <i style='mso-bidi-font-style:normal'>compositionally</i>.
This new algorithm, dubbed SMART, eliminates path explosion due to <span
class=SpellE>interprocedural</span> (<span class=SpellE>interblock</span>)
paths: the number of whole execution paths becomes linear in the number of <span
class=SpellE>intraprocedural</span> paths, instead of being possibly
exponential. Moreover, for programs whose conditional statements can all be
driven using symbolic execution, this efficiency gain is obtained without
losing any precision. A SMART search is key to make
the DART approach (aka systematic dynamic test generation) scalable to large
programs if the goal is to achieve full path coverage (i.e., verification).</p>

The DART technique, also called <i>dynamic test generation</i>,
<i>execution-generated tests</i>, or <i>concolic testing</i>, has
revolutionized automatic test generation, with thousands of citations
to our work and dozens of academic and industrial tools implementing
this approach. This work was the recipient of the HVC 2009 Award.<p>

<b>Whitebox Fuzzing for Security Testing: SAGE</b><p>

In 2006, I joined Microsoft Research and started working on the
"<i>killer app</i>" for DART, namely <i>fuzzing</i>. Fuzzing, or
<i>fuzz testing</i>, is the process of finding security
vulnerabilities in input-parsing code by repeatedly testing the parser
with modified, or fuzzed, inputs. With Michael Levin and several other
Microsoft colleagues including (then-intern) David Molnar, we started
developing SAGE, the first <i>whitebox fuzzer</i> for security
testing. Whitebox fuzzing extends DART from unit testing to security
testing of large programs. SAGE performs dynamic symbolic execution at
the x86 binary level, and implements several optimizations that are
crucial for dealing with huge execution traces with hundreds of
millions of machine instructions, in order to scale to large file
parsers embedded in applications with millions of lines of code, like
Microsoft Excel or PowerPoint. SAGE also pioneered the use of search
heuristics based on code coverage for fuzzing purposes. <p>

Since 2008, SAGE has been running in production for over 1,000
machine-years, automatically fuzzing hundreds of applications. This is
the largest computational usage ever for any
Satisfiability-Modul-Theories (SMT) solver according to the authors of
the Z3 SMT solver (also from Microsoft Research), with around 10
billion constraints processed to date.  During all this fuzzing, SAGE
found many new security vulnerabilities (buffer overflows) in hundreds
of Windows parsers and Office applications, including image
processors, media players, file decoders, and document
parsers. Notably, SAGE found roughly one third of all the bugs
discovered by file fuzzing during the development of Microsoft's
Windows 7, saving (many) millions of dollars by avoiding expensive
security patches for nearly a billion PCs worldwide. In 2012, I was
promoted to "Microsoft Partner" essentially for my work on SAGE and
its successful applications in Microsoft.<p>

Today, whitebox fuzzing has been adopted in many other security-testing tools, and has
inspired numerous variants (such as greybox fuzzing and hybrid
fuzzing) and extensions. Our seminal work on whitebox fuzzing (first
published in 2008) was credited to introducing the "fuzzing" problem
to the program analysis, software engineering, and security academic
communities, with thousands of citations to our work.<p>

<b>Fuzzing in the Cloud: Project Springfield</b><p>

In 2015, with my Microsoft Research colleague David Molnar, I
co-founded Project Springfield, the <i>first commercial cloud fuzzing
service</i>. Customers who subscribe to this cloud service can submit
fuzzing jobs targeting their own software. Fuzzing jobs are processed
by creating many virtual machines in the cloud and by running
different fuzzing tools (including SAGE) and configurations on each of
these machines. Fuzzing results (bugs) are continually collected by
the service and post-processed for analysis, triage and
prioritization, with final results available directly to customers on
a secured website.<p>

Project Springfield operated as a "virtual start-up" (or "special
project") inside Microsoft Research. I served as its CTO for 2
years. Project Springfield was renamed <i>Microsoft Security Risk
Detection</i> in 2017. Later, the project gradually re-focused on
its core technical contributions, in contrast to its initial business
aspirations, and evolved into a cloud fuzzing platform called
<i>OneFuzz</i>, which became open-source in 2020.<p>

<b>Fuzzing the Cloud: RESTler</b><p>

In 2017, with my Microsoft Research colleague Marina Polishchuk and
intern Vaggelis Atlidakis, we started developing RESTler, the <i>first
stateful REST API fuzzing tool</i> for automatically testing cloud
services through their REST APIs and finding security and reliability
bugs in these services. For a given cloud service with an
OpenAPI/Swagger specification, RESTler analyzes its entire
specification, and then generates and executes tests that exercise the
service through its REST API. RESTler intelligently infers
producer-consumer dependencies among request types from the API
specification. During testing, it checks for specific classes of bugs
and dynamically learns how the service behaves from prior service
responses. This intelligence allows RESTler to explore deeper service
states reachable only through specific request sequences (hence the
term "stateful") and to find more bugs.<p>

In 2020, RESTler became open-source, and its usage has been steadily
growing since, both inside and outside Microsoft. Inside Microsoft,
RESTler has found 100s of new bugs in Microsoft Azure, Office365 and
Bing services, including severe critical bugs. At the time of this
writing, RESTler is still under active development.


<p><span style='font-family:"Arial Unicode MS"'><o:p>&nbsp;</o:p></span></p>

</div>

</body>

</html>
